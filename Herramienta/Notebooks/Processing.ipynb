{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d398f47",
   "metadata": {},
   "source": [
    "# Procesado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67872f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geohash2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e3ccc",
   "metadata": {},
   "source": [
    "### Obtener df de geohashes únicos, latitud y longitud de cada geohash y asignar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e78874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    \"\"\"\n",
    "    Procesa un DataFrame realizando las siguientes operaciones.\n",
    "    Pasos:\n",
    "    1. Obtiene valores únicos de geohashes de una columna específica\n",
    "    2. Decodifica geohashes y agrega columnas de Latitud y Longitud\n",
    "    3. Asigna a cada geohash las bandas de frecuencia y CGI que tengan las conexiones para ese geohash\n",
    "\n",
    "    Argumentos:\n",
    "    df (pandas.DataFrame): El DataFrame inicial.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: El DataFrame procesado final.\n",
    "    \"\"\"\n",
    "\n",
    "    columna_geohash = 'Geohash'\n",
    "    valores_unicos = df[columna_geohash].drop_duplicates()\n",
    "    geohash_df = pd.DataFrame({'Geohash': valores_unicos})\n",
    "\n",
    "    geohash_df['geometry'] = geohash_df['Geohash'].apply(lambda x: geohash2.decode_exactly(x)[:2])\n",
    "    geohash_df[['Latitud', 'Longitud']] = geohash_df['geometry'].apply(lambda x: pd.Series([str(x[0]), str(x[1])]))\n",
    "    geohash_df.drop('geometry', axis=1, inplace=True)\n",
    "\n",
    "    geohash_df['BAND_FREQ'] = None\n",
    "    band_freq_unique = df.groupby('Geohash')['BAND_FREQ'].unique()\n",
    "    for index, row in geohash_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        if geohash in band_freq_unique:\n",
    "            geohash_df.at[index, 'BAND_FREQ'] = band_freq_unique[geohash].tolist()\n",
    "    new_rows = []\n",
    "    \n",
    "    for index, row in geohash_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        latitud = row['Latitud']\n",
    "        longitud = row['Longitud']\n",
    "        band_freq_list = row['BAND_FREQ']\n",
    "        for band_freq in band_freq_list:\n",
    "            new_rows.append({'Geohash': geohash, 'Latitud': latitud, 'Longitud': longitud, 'BAND_FREQ': band_freq})\n",
    "    geohash_df = pd.DataFrame(new_rows)\n",
    "    \n",
    "    ci_unicos = df.groupby(['Geohash', 'BAND_FREQ'])['CGI'].apply(lambda x: list(set(x)))\n",
    "    geohash_df['CGI'] = None\n",
    "    for index, row in geohash_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        band_freq = row['BAND_FREQ']\n",
    "        if (geohash, band_freq) in ci_unicos.index:\n",
    "            cell_ids = ci_unicos.loc[(geohash, band_freq)]\n",
    "            geohash_df.at[index, 'CGI'] = cell_ids\n",
    "            \n",
    "    new_rows = []\n",
    "    for index, row in geohash_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        latitud = row['Latitud']\n",
    "        longitud = row['Longitud']\n",
    "        band_freq = row['BAND_FREQ']\n",
    "        cgi_list = row['CGI']\n",
    "        for cgi in cgi_list:\n",
    "            new_rows.append({'Geohash': geohash, 'Latitud': latitud, 'Longitud': longitud,'BAND_FREQ': band_freq,'CGI': cgi})\n",
    "    geohash_df = pd.DataFrame(new_rows)\n",
    "\n",
    "    return geohash_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6cb8e",
   "metadata": {},
   "source": [
    "### Df para RSRP y RSRQ, calcular media de cada variable y número de eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe_rsrp_rsrq(df_copia, df_valores):\n",
    "    \"\"\"\n",
    "    Procesa un DataFrame para calcular métricas RSRP y RSRQ.\n",
    "    Pasos:\n",
    "    1. Crea dos copias del DataFrame, una será para la RSRP y otra para la RSRQ\n",
    "    2. En el caso de la RSRP, calcula la RSRP_media y el número de eventos buscando coincidencias en el DataFrame de \n",
    "       las medidas\n",
    "    3. En el caso de la RSRQ, asigna franja horarias y posteriormente calcula la RSRP_media y el número de eventos buscando \n",
    "       coincidencias en el DataFrame de las medida\n",
    "    \n",
    "    Argumentos:\n",
    "    df_copia (pandas.DataFrame): El DataFrame que se va a copiar para rsrp y rsrq.\n",
    "    df_valores (pandas.DataFrame): El DataFrame del cual se extraen los valores de RSRP y RSRQ.\n",
    "\n",
    "    Returns:\n",
    "    rsrp_df (pandas.DataFrame): El DataFrame que contiene los datos con la RSRP calculada.\n",
    "    rsrq_df (pandas.DataFrame): El DataFrame que contiene los datos con la RSRQ calculada.\n",
    "    \"\"\"\n",
    "\n",
    "    rsrp_df = df_copia.copy()\n",
    "    rsrq_df = df_copia.copy()\n",
    "\n",
    "    rsrp_df['RSRP_media'] = None\n",
    "    rsrp_df['eventos'] = None\n",
    "    for index, row in rsrp_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        band_freq = row['BAND_FREQ']\n",
    "        cgi = row['CGI']\n",
    "        match_rsrp = df_valores[(df_valores['Geohash'] == geohash) & (df_valores['BAND_FREQ'] == band_freq) & (df_valores['CGI'] == cgi)]\n",
    "        if not match_rsrp.empty:\n",
    "            rsrp_df.at[index, 'RSRP_media'] = np.mean(match_rsrp['RSRP'])\n",
    "            rsrp_df.at[index, 'eventos'] = len(match_rsrp)\n",
    "\n",
    "    rsrq_df['Franja_horaria'] = None\n",
    "    for index, row in rsrq_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        band_freq = row['BAND_FREQ']\n",
    "        cgi = row['CGI']\n",
    "        match_franja = df_valores[(df_valores['Geohash'] == geohash) & (df_valores['BAND_FREQ'] == band_freq) & (df_valores['CGI'] == cgi)]\n",
    "        if not match_franja.empty:\n",
    "            franjas = list(set(match_franja['Franja_horaria']))\n",
    "            rsrq_df.at[index, 'Franja_horaria'] = franjas\n",
    "\n",
    "    rsrq_df['Franja_horaria'] = rsrq_df['Franja_horaria'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "    rsrq_df = rsrq_df.explode('Franja_horaria')\n",
    "\n",
    "    rsrq_df['RSRQ_media'] = None\n",
    "    rsrq_df['eventos'] = None\n",
    "    for index, row in rsrq_df.iterrows():\n",
    "        geohash = row['Geohash']\n",
    "        band_freq = row['BAND_FREQ']\n",
    "        cgi = row['CGI']\n",
    "        franja = row['Franja_horaria']\n",
    "        match_rsrq = df_valores[(df_valores['Geohash'] == geohash) & (df_valores['BAND_FREQ'] == band_freq) & (df_valores['CGI'] == cgi) & (df_valores['Franja_horaria'] == franja)]\n",
    "        if not match_rsrq.empty:\n",
    "            rsrq_df.at[index, 'RSRQ_media'] = np.mean(match_rsrq['RSRQ'])\n",
    "            rsrq_df.at[index, 'eventos'] = len(match_rsrq)\n",
    "\n",
    "    rsrp_df = rsrp_df[['Geohash', 'Latitud', 'Longitud', 'BAND_FREQ', 'CGI', 'RSRP_media', 'eventos']]\n",
    "    rsrq_df = rsrq_df[['Geohash', 'Latitud', 'Longitud', 'BAND_FREQ', 'CGI', 'Franja_horaria', 'RSRQ_media', 'eventos']]\n",
    "\n",
    "    return rsrp_df, rsrq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_coincidencias(df1, df2, df3, df4, columns_to_match1 = None, columns_to_match2 = None):\n",
    "    \"\"\"\n",
    "    Compara dos DataFrames con el fin de quedarse únicamente con aquellos datos que estén presentes en ambos Dataframes.\n",
    "\n",
    "    Argumentos:\n",
    "    df1 (pandas.DataFrame): El DataFrame procesado que contiene los datos de RSRP para las medidas del drive test\n",
    "    df2 (pandas.DataFrame): El DataFrame procesado que contiene los datos de RSRP para las medidas crowdsourced\n",
    "    df3 (pandas.DataFrame): El DataFrame procesado que contiene los datos de RSRQ para las medidas del drive test\n",
    "    df4 (pandas.DataFrame): El DataFrame procesado que contiene los datos de RSRQ para las medidas crowdsourced\n",
    "\n",
    "    Returns:\n",
    "    filtered_df1 (pandas.DataFrame): El DataFrame filtrado que contiene los datos de RSRP para las medidas del drive test que \n",
    "                                     estén presentes en el conjunto de datos crowdsourced\n",
    "    filtered_df2 (pandas.DataFrame): El DataFrame filtrado que contiene los datos de RSRP para las medidas crowdsourced que \n",
    "                                     estén presentes en el conjunto de datos del drive test\n",
    "    filtered_df3 (pandas.DataFrame): El DataFrame filtrado que contiene los datos de RSRQ para las medidas del drive test que \n",
    "                                     estén presentes en el conjunto de datos crowdsourced\n",
    "    filtered_df4 (pandas.DataFrame): El DataFrame procesado que contiene los datos de RSRQ para las medidas crowdsourced que \n",
    "                                     estén presentes en el conjunto de datos del drive test\n",
    "    \"\"\"\n",
    "    columns_to_match1 = ['Geohash', 'BAND_FREQ', 'CGI']\n",
    "    columns_to_match2 = ['Geohash', 'BAND_FREQ', 'CGI', 'Franja_horaria']\n",
    "    def filtrar(df_a, df_b, cols):\n",
    "        filtered_a = pd.DataFrame(columns=df_a.columns)\n",
    "        filtered_b = pd.DataFrame(columns=df_b.columns)\n",
    "        \n",
    "        for _, row in df_a.iterrows():\n",
    "            coincidencia = df_b\n",
    "            for col in cols:\n",
    "                coincidencia = coincidencia[coincidencia[col] == row[col]]\n",
    "            if not coincidencia.empty:\n",
    "                filtered_a = pd.concat([filtered_a, row.to_frame().T])\n",
    "        \n",
    "        for _, row in df_b.iterrows():\n",
    "            coincidencia = df_a\n",
    "            for col in cols:\n",
    "                coincidencia = coincidencia[coincidencia[col] == row[col]]\n",
    "            if not coincidencia.empty:\n",
    "                filtered_b = pd.concat([filtered_b, row.to_frame().T])\n",
    "        \n",
    "        filtered_a.reset_index(drop=True, inplace=True)\n",
    "        filtered_b.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return filtered_a, filtered_b\n",
    "    \n",
    "    filtered_df1, filtered_df2 = filtrar(df1, df2, columns_to_match1)\n",
    "    filtered_df3, filtered_df4 = filtrar(df3, df4, columns_to_match2)\n",
    "    \n",
    "    return filtered_df1, filtered_df2, filtered_df3, filtered_df4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
